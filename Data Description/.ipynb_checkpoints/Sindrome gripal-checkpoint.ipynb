{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/home/juliane_oliveira/spark-2.3.1-bin-hadoop2.7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install funcao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import date\n",
    "import functools\n",
    "from IPython.core.display import display, HTML\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def unionAll(*dfs):\n",
    "#    if not dfs:\n",
    "#        raise ValueError()\n",
    "#    first = dfs[0]\n",
    "#    return df.sql_ctx.createDataFrame(\n",
    "#        df._sc.union([df.rdd for df in dfs]), first.schema\n",
    "#    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to combine all dfs Alternativo\n",
    "def unionAll(dfs):\n",
    "    return reduce(lambda df1,df2: df1.union(df2.select(df1.columns)), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aumentando a largura do notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iniciando spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Sindrome Gripal').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando lista de dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/media/juliane_oliveira/My Passport/PAMEpi_datalake/raw_data_covid19_version-21-11-23/data-notificacao_sindrome_gripal/\"\n",
    "path_to_export = \"/media/juliane_oliveira/My Passport/GitHub/Data of git computations/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "files = glob.glob(path + '*', recursive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dfs = [spark.read.csv(os.path.join(os.path.expanduser(path), x), header=True, sep=';') for x in os.listdir(path) if x.startswith('dados_utf8')]\n",
    "#print(len(dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "# contando arquivos carregados corretamente\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = spark. read. csv(files[0], header=True,sep=';',encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files read: 1\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 2\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 3\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 4\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 5\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 6\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 7\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 8\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 9\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 10\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 11\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 12\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 13\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 14\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 15\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 16\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 17\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 18\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 19\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 20\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 21\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 22\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 23\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 24\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 25\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 26\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 27\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 28\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 29\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 30\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 31\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 32\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 33\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 34\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 35\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 36\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 37\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 38\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 39\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 40\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 41\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 42\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 43\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 44\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 45\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 46\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 47\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 48\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 49\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 50\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 51\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 52\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 53\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 54\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 55\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 56\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 57\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 58\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 59\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 60\n",
      "************************************************Processing files************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files read: 61\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 62\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 63\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 64\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 65\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 66\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 67\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 68\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 69\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 70\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 71\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 72\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 73\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 74\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 75\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 76\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 77\n",
      "************************************************Processing files************************************************\n",
      "Number of files read: 78\n",
      "************************************************Processing files************************************************\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "    \n",
    "for base in files:\n",
    "    dfs.append(spark.read.csv(base, header = True, sep=';', encoding=\"ISO-8859-1\", inferSchema = True))\n",
    "    print(\"Number of files read: {}\".format(len(dfs)))\n",
    "    print('{:*{align}{width}}'.format('Processing files', align='^', width='112'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = unionAll(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+--------------------+-----------+--------------------+--------------------+--------------+----------+---------+--------+----------+---------------+-------------+---------+-----------------+---------------------+--------------------+------------------------+---------+---------+-----+-------------------+--------------------+--------------------+\n",
      "|       ÿid|     dataNotificacao|  dataInicioSintomas|      dataNascimento|            sintomas|profissionalSaude|                 cbo|           condicoes|estadoTeste|           dataTeste|           tipoTeste|resultadoTeste|paisOrigem|     sexo|  estado|estadoIBGE|      municipio|municipioIBGE|   origem|estadoNotificacao|estadoNotificacaoIBGE|municipioNotificacao|municipioNotificacaoIBGE| excluido| validado|idade|   dataEncerramento|        evolucaoCaso|  classificacaoFinal|\n",
      "+----------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+--------------------+-----------+--------------------+--------------------+--------------+----------+---------+--------+----------+---------------+-------------+---------+-----------------+---------------------+--------------------+------------------------+---------+---------+-----+-------------------+--------------------+--------------------+\n",
      "|gINnMy6CdU|2020-06-17T20:08:...|2020-06-08T03:00:...|1989-12-26T02:00:...|Dor de Garganta, ...|              Não|                null|                null|  Concluído|2020-06-16T03:00:...|TESTE RÁPIDO - AN...|      Positivo|      null| Feminino|    Acre|        12|       Tarauacá|      1200609|undefined|             Acre|                   12|            Tarauacá|                 1200609|undefined|undefined|   31|2020-06-17 00:00:00|Em tratamento dom...|Confirmado Labora...|\n",
      "|TiABR1GOmb|2020-06-13T03:00:...|2020-06-07T03:00:...|1998-11-14T02:00:...|Dispneia, Dor de ...|              Não|                null|                null|  Concluído|2020-06-13T03:00:...|TESTE RÁPIDO - AN...|      Negativo|      null| Feminino|    Acre|        12|       Capixaba|      1200179|undefined|             Acre|                   12|            Capixaba|                 1200179|undefined|undefined|   22|               null|                null|                null|\n",
      "|RG9f49BW1b|2020-06-12T05:00:...|2020-05-29T05:00:...|1954-01-28T05:00:...|       Febre, Outros|              Não|                null|Doenças cardíacas...|  Concluído|2020-06-12T05:00:...|TESTE RÁPIDO - AN...|      Positivo|      null|Masculino|    Acre|        12|Cruzeiro do Sul|      1200203|undefined|             Acre|                   12|     Cruzeiro do Sul|                 1200203|undefined|undefined|   67|               null|                null|                null|\n",
      "|F66wawHqyP|2020-05-09T05:00:...|2020-05-02T05:00:...|1984-07-16T05:00:...|        Febre, Tosse|              Não|                null|                null|  Concluído|2020-05-09T05:00:...|              RT-PCR|      Positivo|      null|Masculino|    Acre|        12|     Rio Branco|      1200401|undefined|             Acre|                   12|          Rio Branco|                 1200401|undefined|undefined|   37|2020-05-27 02:00:00|                Cura|Confirmado Labora...|\n",
      "|Gq5GXKSRZY|2020-05-23T03:00:...|2020-05-10T03:00:...|1991-09-21T03:00:...|              Outros|              Sim|1312 - Gestores e...|                null|  Concluído|2020-05-23T04:00:...|TESTE RÁPIDO - AN...|      Negativo|      null| Feminino|Rondônia|        11|      Ariquemes|      1100023|undefined|             Acre|                   12|            Capixaba|                 1200179|undefined|undefined|   29|               null|                null|          Descartado|\n",
      "+----------+--------------------+--------------------+--------------------+--------------------+-----------------+--------------------+--------------------+-----------+--------------------+--------------------+--------------+----------+---------+--------+----------+---------------+-------------+---------+-----------------+---------------------+--------------------+------------------------+---------+---------+-----+-------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
